{"pages":[],"posts":[{"title":"DeepFM理论与其应用","text":"DeepFM[1]是哈工大Guo博士在华为诺亚实验室实习期间，提出的一种深度学习方法，它基于Google的经典论文Wide&amp;Deep learning 基础上，通过将原论文的wide部分–LR部分替换成FM[4]，从而改进了原模型依然需要人工特征工程的缺点，得到一个end to end 的深度学习模型。DeepFM在企业数据集(华为应用商店)和公开数据集(criteo)上都取得不错的效果，目前该方法在不少互联网公司的推荐、广告系统中得到了较为广泛的应用。 1. CTR预估中的特征分析在CTR预测中，挖掘用户行为中的隐藏特征以及它们之间的交叉特征已经成为推荐算法中最核心的一部分。华为通过对自己应用市场的用户进行行为分析，得到以下两个重要的结论。 用户喜欢在等待外卖送达的时段下载APP。它说明时间和APP类别的二维特征交叉是一个有效的特征输入信号。 青少年的男性用户喜欢下载射击或者RPG游戏APP。它则说明年龄、性别、APP类别的三维特征交叉也是一个有效的输入信号。 我们可以看到，CTR预估中主要挑战是有效对特征交互建模，有些特征交互可以很容易理解，因此特征工程的专家可以人工设计出来。然而，绝大部分特征都是隐藏在数据背后，难以形成专家的先验知识，只能通过机器学习自动生成。由于实际应用中使用到的特征非常多(原始特征经常有几十到上百维)，就算是简单的特征交互，专家其实也无法对全部特征交叉进行有效建模。 广义线性模型实现简单、性能好，但是缺乏学习特征交叉的能力，通常在工业实践中会人工做特征工程来解决这个问题。FM采用隐向量(latent vector)的内积作为对特征交叉的建模方法，具有很好的效果，FM在深度学习时代之前是CTR预估最为广泛应用的一种算法，它在实践中通常只会利用二维的特征交叉。 总而言之，用户行为的特征维度是高度复杂的，无论是低维还是高维的特征交叉都会起到重要的作用。根据Google wide&amp;deep model，它在建模过程中同时考虑了低维和高维的特征交叉，以提升模型的效果。 2.深度学习在CTR预估的进展Google的Wide &amp; Deep Learning for Recommender Systems[2]是深度学习应用于推荐、广告等CTR领域的重要论文。过去几年，神经网络已经在图像、音频等领域得到广泛应用，而由于推荐、广告等领域由于数据的稀疏性、离散性，无法直接套用传统的深度学习模型。 基于深度学习的思想，Google 提出一种深度模块和广度模块结合的神经网络模型。Wide端使用常见的LR(FTRL[5]实现)模型，将常见的离散特征、低维特征组合作为输入，实现了模型的记忆能力。换句话说，模型能够很好记住用户的喜好，给用户推荐 常见喜好 的内容。Deep端将离散特征通过embedding方法转化成稠密特征向量输入，实际上实现了tag向量的模糊查询，扩充了模型的泛化能力。换句话说，模型能够更好理解用户-物品之间内在的高维关系，给用户推荐 罕见但是可能喜好 的内容，破解“信息茧房”的问题。 ###2.1 稀疏特征的优点： LR, DNN在底层还是一个线性模型，但是现实生活中，标签y与特征x之间较少存在线性关系，而往往是分段的。以”点击率 ~ 历史曝光次数” 之间的关系为例，之前曝光过1、2次的时候，“点击率 ~ 历史曝光次数”之间一般是正相关的，再多曝光1、2次，用户由于好奇，没准就点击了；但是，如果已经曝光过8、9次了，由于用户已经失去了新鲜感，越多曝光，用户越不可能再点，这时“点击率 ~ 历史曝光次数”就表现出负相关性。因此，categorical特征相比于numeric特征，更加符合现实场景。 推荐、搜索一般都是基于用户、商品的标签画像系统，而标签天生就是categorical的 稀疏的类别/ID类特征，可以稀疏地存储、传输、运算，提升运算效率。 ###2.2 稀疏特征的缺点： 稀疏的categorical/ID类特征，也有着单个特征表达能力弱、特征组合爆炸、分布不均匀导致受训程度不均匀的缺点。 FTRL 充分输入的稀疏性在线更新模型，训练出的模型也是稀疏的，便于快速预测。 Parameter Server，充分利用特征的稀疏性，不必在各机器之间同步全部模型，而让每台机器“按需”同步自己所需要的部分模型权重，“按需”上传这一部分权重的梯度。 TensorFlow Feature Column类，除了一个numeric_column是处理实数特征的，其实的都是围绕处理categorical特征的，封装了常见的分桶、交叉、哈希等操作。 总而言之： Wide for Memorization，wide侧记住的是历史数据中那些常见、高频的模式。根据人工经验、业务背景，将有价值的、显而易见的特征及特征组合输入wide侧。 Deep for Generation，deep侧通过embedding将tag向量化，变tag的精确匹配，为tag向量的模糊查询，因而模型具备良好的“扩展”能力。 Wide &amp; Deep模型应用Google Play的数据，它包含超过10亿活跃用户以及上百万的app行为。在线实验显示Wide&amp; Deep model 有效提升了App的购买率。代码开源集成到了TensorFlow内，调用DNNLinearCombinedClassifier 这个estimator就可以。 123456789101112estimator = DNNLinearCombinedClassifier( # wide侧设置 linear_feature_columns=[categorical_feature_a_x_categorical_feature_b], linear_optimizer=tf.train.FtrlOptimizer(...), # deep侧设置 dnn_feature_columns=[ categorical_feature_a_emb, categorical_feature_b_emb, numeric_feature], dnn_hidden_units=[1000, 500, 100], dnn_optimizer=tf.train.ProximalAdagradOptimizer(...), # warm-start 设置 warm_start_from=\"/path/to/checkpoint/dir\") 除了Wide and Deep 以外还有数篇文章探索深度学习在CTR预估领域的应用，其中包括采用FM对特征做初始化处理的FNN[3]。FNN通过它的模型如下图所示： 它主要缺点在于，embedding 后的特征可能会被FM模型过度影响。使用FM对特征做预处理的做法，可能影响了模型的性能和效率。它只能刻画高维的特征交互，而不像Wide &amp; Deep那样高维和低维特征交叉都能刻画到。 3.DeepFM核心思想DeepFM将Wide and Deep 模型中的Wide侧的LR替换成FM，克服了原有模型依然需要对低维特征做特征工程的缺点，实现了一个无需任何人工特征工程的end to end 模型。DeepFM在wide侧和deep侧共享了embedding的特征向量。 可以看到DeepFM的数学形式化：$$y=sigmod(yFM +yDNN)$$ yFM 是FM组件的输出，yDNN是深度组件的输出结果。FM组件能够捕获一维特征的同时，还能很好捕获二维稀疏组合特征。如下图所示： yDNN旨在学习高维特征组合，和图像、音频的稠密数值张量不同的是，在推荐系统中DNN模型的数据输入通常都是非常稀疏的张量，所以在技术上一般会采用embedding层来压缩数据空间维度。 DeepFM 在企业数据集(华为应用商店)和公开数据集(criteo)进行多次实验，采用AUC和LogLoss来评估效果。具体效果如下图所示： DeepFM在公开数据上，比LR&amp;DNN AUC提升了一百多个基点，是一个非常好的改进。 4. DeepFM重要参数这篇文章有趣的部分是探索与分享整个模型的多个超参，从而分析如何得到一个更好效果的模型。 ###4.1 激活函数relu 函数和 tanh 函数比sigmod函数效果更好。 4.2 Dropout下图效果显示：采用适合的随机性能够加强模型的鲁棒性，建议采用dropout比率在0.6~0.9之间。 4.3 每层神经元个数建议采用200~400个神经元能够给模型更好效果。 4.4 隐含层数量增加隐含层的数量能够一定程度提升模型效果，但是要注意过拟合的情况。建议3~5个隐藏层为妙。 4.5 网络结构文章中测试了四种深度网络结构，不变型(constant),增长型(increasing),衰减型(decreasing),钻石型(diamond)。文章保证四种网络结构神经元总量一致，采用三层隐藏层，从而四种形状具体为：constant (200-200-200), increasing (100- 200-300), decreasing (300-200-100), and diamond (150-300- 150).如下图所示，constant型效果更好。这点比较有意思，因为在Wide &amp; Deep Model中，采用的是decreasing型。网络结构的效果也取决于实验数据本身。 5. DeepFM的实现DeepCTR[6]是一个实现了多种深度CTR预估模型的python库，下面引用它基于criteo数据，所实现的DeepFM样例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import pandas as pdfrom sklearn.metrics import log_loss, roc_auc_scorefrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import LabelEncoder, MinMaxScalerfrom deepctr.models import DeepFMfrom deepctr.utils import SingleFeatif __name__ == &quot;__main__&quot;: data = pd.read_csv(&apos;./criteo_sample.txt&apos;) #拆分稀疏和稠密特征 sparse_features = [&apos;C&apos; + str(i) for i in range(1, 27)] dense_features = [&apos;I&apos; + str(i) for i in range(1, 14)] data[sparse_features] = data[sparse_features].fillna(&apos;-1&apos;, ) data[dense_features] = data[dense_features].fillna(0, ) target = [&apos;label&apos;] # 1.类别特征的编码与稠密特征做归一化 for feat in sparse_features: lbe = LabelEncoder() data[feat] = lbe.fit_transform(data[feat]) mms = MinMaxScaler(feature_range=(0, 1)) data[dense_features] = mms.fit_transform(data[dense_features]) # 2.统计稀疏特征类别特征个数，记录稠密特征类目 sparse_feature_list = [SingleFeat(feat, data[feat].nunique()) for feat in sparse_features] dense_feature_list = [SingleFeat(feat, 0,) for feat in dense_features] # 3.生成模型输入特征 train, test = train_test_split(data, test_size=0.2) train_model_input = [train[feat.name].values for feat in sparse_feature_list] + \\ [train[feat.name].values for feat in dense_feature_list] test_model_input = [test[feat.name].values for feat in sparse_feature_list] + \\ [test[feat.name].values for feat in dense_feature_list] # 4.定义模型、预测、评估模型 model = DeepFM({&quot;sparse&quot;: sparse_feature_list, &quot;dense&quot;: dense_feature_list}, task=&apos;binary&apos;) model.compile(&quot;adam&quot;, &quot;binary_crossentropy&quot;, metrics=[&apos;binary_crossentropy&apos;], ) history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2, ) pred_ans = model.predict(test_model_input, batch_size=256) print(&quot;test LogLoss&quot;, round(log_loss(test[target].values, pred_ans), 4)) print(&quot;test AUC&quot;, round(roc_auc_score(test[target].values, pred_ans), 4)) 引用[1] Guo, Huifeng, et al. “DeepFM: a factorization-machine based neural network for CTR prediction.” arXiv preprint arXiv:1703.04247 (2017).[2] Cheng, Heng-Tze, et al. “Wide &amp; deep learning for recommender systems.” Proceedings of the 1st workshop on deep learning for recommender systems. ACM, 2016.[3] Zhang, Weinan, Tianming Du, and Jun Wang. “Deep learning over multi-field categorical data.” European conference on information retrieval. Springer, Cham, 2016.[4] Rendle, Steffen. “Factorization machines.” 2010 IEEE International Conference on Data Mining. IEEE, 2010.[5] McMahan, H. Brendan. “Follow-the-regularized-leader and mirror descent: Equivalence theorems and l1 regularization.” (2011).[6] DeepCTR https://github.com/shenweichen/DeepCTR","link":"/2019/06/24/DeepFM理论与其应用/"},{"title":"推荐资料汇总与解说","text":"最近和好几位朋友讨论推荐系统的搭建和升级，暂时没空将全部实践过的部分都写出来，但是看过的资料和论文倒是一气呵成地梳理出来，对想从零搭建一个推荐系统或者对推荐系统现有效果不满希望升级的同学来说，可能有用，也可能没用，你都已经看过。 1. 架构部分 头条首席架构师曹欢欢的分享，为了让业界了解头条的算法，比较清晰扼要，突出重点，没有讲最新的内容。但是核心都涉及到，值得反复研读。基本上绝大部分推荐系统架构和头条一致。当中的差异主要体现在实时框架上，头条继承百度系的搜索架构思想，喜欢用倒排索引来实现很多部件。阿里、腾讯更加倾向于类似于Strom的流式计算加上KV存储的方式。个人认为并无高低之分，看架构师、负责人喜好和团队技能分布。36氪首发 | 今日头条推荐算法原理全文详解今日头条成功的核心技术秘诀是什么？深度解密个性化资讯推荐技术 爱奇艺的推荐架构演化，有整体架构、算法模型的升级进化过程，从算法产品的角度来讲述不同的算法模型演化和效果过程，是一个值得follow的演化路径。可能在爱奇艺的数据上，这些模型的效果如此好。实际上，在大量其他公司的实践和paper，可能同样的算法模型不一定做的出来一样的效果。爱奇艺个性化推荐排序实践 业界解读youtube推荐算法模型，这篇文章值得去看的是，如何设计观测指标，如何评估内容。从YouTube算法论文反推其推荐机制 如何破解YouTube视频推荐算法？ 饿了么的推荐架构，包含一部分LBS的领域知识，整体架构也比较清晰。推进的路径也不错，EE的应用也重视的很好。回顾·外卖推荐算法中有哪些机制与手段？ 糖豆的实践，第一期比较稚嫩，但是0到1是gain最大的时候，极少人力就能快速上线，建立良好的评估基线极其重要。包括了实时、深度学习、强化学习等内容，有些零散，但是比较直接面对具体的一个推荐系统阶段。上述的文章一般不会这么详细。糖豆推荐系统第一期开发与评估报告糖豆实时推荐系统设计与实现单步强化学习在糖豆推荐系统的应用深度学习于糖豆推荐应用–图片模糊识别第二期后续的工作我一直没空写,以后有空写一下，大概包括算法演进、语义挖掘、用户画像、深度学习的尝试等。 2. 模型部分2.1 基础的推荐模型包括基于流行度，基于协同过滤，基于内容等模型。这些模型都比较简单却非常有效，一般作为候选集的选择或者粗排去使用或者推荐系统初期模型，这些都是非CTR预估模型。Collaborative Filtering based Recommendation Systems exemplifiedBeginners Guide to learn about Content Based Recommender Engines ####2.2 LR及其推广模型 LR它是基线模型，后续所有模型都要和它对比。离线对比的指标主要是AUC，logloss，RMSE，NDCG等等，最好都看，个人主要看AUC。我这里面介绍就简单讲AUC为主。LR模型虽然非常简单，但是特征工程+LR基本能解决大部分推荐的问题。它的缺点当然非常多，包括学习能力有效，需要领域知识实现特征之间的交叉组合等等。但是后续会介绍的大量模型里面(在我看过的paper里面),没有一个模型敢说超越LR 20%以上的(公开数据集)。LR AUC最好能做到0.76~0.78，depend on 数据集。一般建议把LR AUC起码做到0.72左右，再进行下一步模型升级。Recommendation System Using Logistic Regression and the Hashing Trick FTRL它是谷歌提出来的在线学习模型，它实际上是对LR的GD过程做了在线的算法和实现优化。适合于极大级别的实时预测。Follow-the-Regularized-Leader and Mirror Descent:Equivalence Theorems and L1 Regularization MLR它是阿里盖坤团队提出的LR模型的推广。MLR大概就是采用一个级联器组合了LR，能够通过空间分片的方法来逼近任何高维空间的非线性分类面。在阿里妈妈的广告方面应用比较广泛。Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction 2.3 基于隐变量的模型 SVD矩阵分解的方法，它是多年前推荐系统的圣杯– Netflix Prize最终获奖模型 – SVD++集成RBM，比Netflix当时的模型提升了10%，这是一个恐怖的提升。它思想是用户对物品喜好程度(隐向量)可以用用户-物品大矩阵来表达，通过已知的用户对物品行为推断用户对其他为接触物品的喜好程度。具体算法实现就是将大矩阵分解为user 和item两个小矩阵，用最小二乘法求解得到。但是它在实现上比较麻烦，Spark对SVD的实现性能不算太好。同时模型解释性也比较差。Netflix Prize and SVDSpark SVD FM因子分解机的方法，纯粹的矩阵分解无法融入用户、物品的特征。FM能够结合显性变量和隐性变量，模型能够有效表达特征组合(实际应用基本只是两两组合)，允许稀疏高维特征空间的参数估计。Factorization Machines深入FFM原理与实践 FM的改进版本包括FFM等等，都在百度、美团等公司的广告、推荐等系统广泛使用。 2.4 Tree-based ensemble模型 GBDT+LR它是Facebook提出的经典模型，最核心地方是省去人工做特征工程的部分。AUC 有可能能做到0.8。这个模型有些人直接简化成用GBDT来预测，不同场景表现不太一样，但基本差异不大。它的缺点，其实就是Tree model的缺点，整体来讲model是历史数据的记忆，推广性较差。Practical Lessons from Predicting Clicks on Ads atFacebook很多人喜欢用XGBoost框架，个人认为Spark的GBDT、LightGBM也差别不大。 GBDT+FM基于FB这个思路,FM比LR能更好表达二维组合交叉特征，GBDT+FM能够在大规模稀疏特征空间有不错的性能表现。方法在Kaggle竞赛中拿到不错的名次。前些年ensemble框架是极其流行，工业界应用也是非常广泛。2nd place solution for Avazu click-through rate prediction competition 2.5 基于深度学习的模型 Wide &amp; Deep Model以上基本都是传统ML的方法，它们有极其大量的变种和改进，但是思路没有本质变化。Wide &amp; Deep Model 是google 提出的基于深度学习框架的CTR预估模型，它在youtube应用效果不错。它作用不止于此，属于用深度学习打开了传统CTR预估的大门，同时集成了传统ML和深度学习的优点。后续有无数的基于wide &amp; deep 思想的深度学习的CTR预估模型算法。https://arxiv.org/pdf/1606.07792.pdf DCNGoogle提出的深度组合网络，在DNN基础上通过加入cross网络，能够在每层自动化进行特征组合。效果上主要对比了LogLoss，比LR有显著提升，比DNN也有一定提升。Deep &amp; Cross Network for Ad Click Predictions DIN。 深度兴趣网络，阿里提出来的深度学习CTR预估模型，应用在阿里妈妈的广告预估上。主要是通过embedding的学习和多层感知机组合在端到端学习里面。前者刻画了淘宝用户的多重兴趣，后者将多种行为聚合成单一向量，据说效果非常好。https://arxiv.org/pdf/1706.06978.pdf DeepFM。 FM是不错的ML模型，用深度学习来结合，得到一个更强的模型。https://www.ijcai.org/proceedings/2017/0239.pdf 3. 其他部分可以看到推荐系统不是一个简单的工程，涉及到内容、产品策略、客户端、服务端、大数据、推荐工程、推荐算法、评估体系等等一系列，这些组件环环相扣，存在大量变量和组合，也有漫长的迭代周期，相信每个公司在实践过程中有大量的独特的体验和收获。过去的关于所有这些推荐系统的建设经验局限于时间和工作因素，没有全部都写完， 以下还有补充两个部分，抛砖引玉 。 • AB测试平台是线上评估的必须。https://www.jianshu.com/p/2fcdd25d3499 • 大数据的埋点非常重要，准备好最充分的数据原材料https://www.jianshu.com/p/d45235b51601 本来还有实验部分、评估部分、实战内容，但是我当时比较困了，就不想写了。","link":"/2019/06/24/推荐资料汇总与解说/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/06/22/hello-world/"},{"title":"一站式机器学习平台资源介绍","text":"1. 缘起近日和公司同学分享了推荐系统的构建、策略、算法等相关内容。由于课程长度缘故，来不及和大家实践一下，如何实现一个简单推荐系统的CTR预估模型。于是，课后想分享一个基于Jupyter Notebook的demo，发现居然一时间找不到国内可以用于分享、协作、运行的机器学习平台。通过google找到了几个一站式的机器学习平台，它们的特点都是基于Jupyter Notebook 构建的，都能够在上面开发、调试、训练、运行、分享机器学习相关的代码集和数据集。 1.1 Jupyter NoteBook首先回顾介绍Jupyter Notebook，根据官网的介绍，Jupyter是一种可以允许用户创建、分享代码、公式、可视化等富文本的web 应用。用户通常在上面做数据清洗、数据转换、数值计算、统计建模、机器学习等等。可以说Jupyter是数据科学家最常用、最好用的工具之一，可以快速的对数据处理、可视化、建模，可以说是数据科学的事实标准编辑器了。 1.2 免费平台资源 平台名称 计算核心 核心运行时 内存 存储 支持语言 google colab CPU 2cores /GPU tesla k80s 1core/TPU 8cores 12个小时 12G 50G py2,py3 kaggle kernel CPU 4 cores/GPU 2cores 6个小时 16G/12G 1G py2,py3 Azure Notebooks 未知 未知 4GB 1G py2,py3,R,F# 一般而言，你用GPU训练一个模型，平台提供的内存资源会相应减少一些。在一些评测中，google的GPU比TPU性能稍微强劲些。总体而言，Google colab更加适合较为大型的模型的训练。 1.3 收费平台资源不同的平台有不同的收费标准，基本上可以看做是函数计算的云服务在售卖，本质上比 AI as services 底层一点，基础收费方案，大约在一个月10刀左右。 floydhub如下图所示，可以看到，主力方案，基本提供100G存储，使用的是NVIDIA的Tesla K80或者V100.但是需要注意这些资源都是抢占式的，运行时可以长达7天，一般能用上完整的GPU，内存在60G左右。 ####paperspace如下图所示,paperspace使用的内核和内存方案类似于floyhub，但是有一定GPU并发，以及notebook的限制。 当然，你还可以购买一台GPU Server 部署直接的Jupyter notebook。amazon,google,azure都有自己方案，那么价格就远贵于AI as service的供应商服务啦。 2.Google Colabgoogle colab 是以上介绍平台中，最适合个人开发者的。它不仅仅是提供切实可用的计算、存储资源，它的文件是默认存储在google drive中，也能够集成GitHub做版本控制。同时还可以安装第三方python包，读写第三方的数据源，还能很轻松分享notebook文件。 打开首个google colab notebook，如下图所示： 可以通过修改设置，选择你的代码运行环境，google支持py2和py3，硬件加速支持CPU、GPU、TPU。 可以通过代码查看底层所分配的硬件资源。 12from tensorflow.python.client import device_libdevice_lib.list_local_devices() 可以通过 google colab 的库，上传本地文件。文件会临时存储在content目录下。 123456789from google.colab import filesuploaded = files.upload()for fn in uploaded.keys(): print('User uploaded file \"{name}\" with length {length} bytes'.format( name=fn, length=len(uploaded[fn])))for name, data in uploaded.items(): with open(name, 'wb') as f: f.write(data) print ('saved file', name) 简而言之，google colab是很好的一站式机器学习平台，值得信赖、使用。google colab拥有的能力远超文章所列举，只待各位good coding~","link":"/2019/06/24/一站式机器学习平台资源介绍/"},{"title":"我眼中的云计算","text":"很多人认为云计算是谷歌和亚马逊最早在2006年使用“云计算”这个词，来描述用户按需使用在互联网上使用软件、接入算力、存储文件这个全新的范式。但是 MIT Technology Review 却将云计算术语的起源，追溯到1996年康柏的一个小组的技术人员描绘了互联网商业前景，并将其称之为云计算。他们的愿景详细而且准确。不只是所有商业软件会迁移上网，而且他们命名了“基于云计算的应用” “cloud computing-enabled applications”比如用户文件存储会变得很普遍。在现代背景下首次使用“云计算”发生在2006年8月9日，当时谷歌CEO埃里克施密特将这一术语引入了行业会议。 “现在有趣的是，有一种新兴的新模式，”施密特说，“我认为人们并不真正了解这个机会究竟有多大。它的前提是数据服务和体系结构应该在服务器上。我们称之为云计算 - 他们应该在某个地方“云”。“在亚马逊，微软和IBM等公司开始推动云计算工作之后，该术语在第二年开始得到更广泛的使用。这也是它首次出现在报纸文章中，例如2007年11月15日的纽约时报报道，其标题为“I.B.M.推动“云计算”，“利用远方的数据。”它描述了“基于互联网的超级计算”的模糊计划。时至今日，云计算已经是家喻户晓，它应该是当今最火热的一个技术名词了。在世界最大的搜索引擎谷歌上搜索”cloud computing”，可以显示有3亿8千万个结果，搜索中文“云计算”也有5500万个结果。 1. 风起Buzzword 云计算也已经成为无处不在的行话，烦人但无法避免。 云是互联网的隐喻，也是互联网的品牌重塑。这就是为什么会有激烈争论的原因。 由于是一个隐喻，它可以接受不同的解释。当然它也值得去花钱。 亚马逊SOA GAE的崛起 学术界的云 什么做的云 2.云涌 微软的逆袭 阿里的宝藏 反对者和落败者 3. 心动 腾讯的追赶 百度的转向 人工智能与云计算 4. 志未移 新玩家 云的下半场","link":"/2019/06/22/我眼中的云计算/"},{"title":"胡椒全球史读书笔记","text":"","link":"/2019/06/22/胡椒全球史读书笔记/"}],"tags":[{"name":"recommendation system","slug":"recommendation-system","link":"/tags/recommendation-system/"},{"name":"history","slug":"history","link":"/tags/history/"},{"name":"cloud computing","slug":"cloud-computing","link":"/tags/cloud-computing/"},{"name":"-ml","slug":"ml","link":"/tags/ml/"}],"categories":[]}